# 🧠 Data Ingestion From Different Sources Showcase

Welcome to my **Data Ingestion From Different Sources** portfolio project! As a career changer currently enrolled in a Data Analytics bootcamp, I'm gaining hands-on experience working with diverse data sources. This repository demonstrates how I connect to and extract data from Flat files, Relational databases, Web APIs and webpages, JSON files and Open datasets via Kaggle, which is a critical step in the data analysis pipeline.

---

## 📂 Files Used

```bash
├── dschools.csv                 # Sample CSV file
├── sampled.xls                  # Sample Excel file
├── schools.json                 # Sample JSON file
├── webpagetable.csv             # Web-scraped HTML table exported to CSV
└── data_ingestion.ipynb         # All Python code demonstrating ingestion methods

---

## 🛠️ Technologies Used

- `pandas` – for data manipulation and loading  
- `pyodbc` – to connect to SQL Server  
- `mysql-connector-python` – to connect to MySQL  
- `sqlalchemy` + `pymysql` – cleaner and modern way to access MySQL databases  
- `requests` & `BeautifulSoup` – to scrape data from webpages  
- `opendatasets` – for downloading datasets from Kaggle  
- `json` – to load data from JSON files  

---

## 💡 Key Learnings

- Gained practical experience connecting to **SQL Server** and **MySQL** using both low-level and high-level Python libraries.  
- Learned to scrape and parse **HTML tables** using `pandas.read_html()` and `BeautifulSoup`.  
- Integrated **open datasets** from platforms like Kaggle using API access.  
- Used `SQLAlchemy` to build more robust and reusable database connections.  

---

## 🚀 Getting Started

### Prerequisites
Install the required packages:

```bash
pip install pandas pyodbc mysql-connector-python sqlalchemy pymysql opendatasets beautifulsoup4 requests xlrd
```

### Run the script

Make sure your sample data files are in the same directory, then run:

```bash
python data_ingestion.ipynb
```

---

## 🔒 Disclaimer

This project uses **placeholder credentials** and database names. Please replace them with your actual values when replicating the code. **Never commit real passwords or sensitive data** to public repositories.

---

## 📈 About Me

I'm an aspiring data analyst making a career pivot from a non-tech background. I'm passionate about transforming raw data into meaningful insights and am currently building my portfolio through hands-on projects like this one.

Feel free to connect with me on [LinkedIn](https://www.linkedin.com/in/li-shan-80980a1b9/) or check out more projects on my [GitHub](https://github.com/cyndishan).

---

## 📬 Contact

📧 Email: cyndi.shan0101@gmail.com  
🌐 Portfolio: [LinkedIn](https://www.linkedin.com/in/li-shan-80980a1b9/)

---
